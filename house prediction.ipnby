{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import sgd, adam\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>median age</th>\n",
       "      <th>T_room</th>\n",
       "      <th>T_bedroom</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>income</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-114.31</td>\n",
       "      <td>34.19</td>\n",
       "      <td>15</td>\n",
       "      <td>5612</td>\n",
       "      <td>1283</td>\n",
       "      <td>1015</td>\n",
       "      <td>472</td>\n",
       "      <td>1.4936</td>\n",
       "      <td>66900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-114.47</td>\n",
       "      <td>34.40</td>\n",
       "      <td>19</td>\n",
       "      <td>7650</td>\n",
       "      <td>1901</td>\n",
       "      <td>1129</td>\n",
       "      <td>463</td>\n",
       "      <td>1.8200</td>\n",
       "      <td>80100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-114.56</td>\n",
       "      <td>33.69</td>\n",
       "      <td>17</td>\n",
       "      <td>720</td>\n",
       "      <td>174</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>1.6509</td>\n",
       "      <td>85700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.64</td>\n",
       "      <td>14</td>\n",
       "      <td>1501</td>\n",
       "      <td>337</td>\n",
       "      <td>515</td>\n",
       "      <td>226</td>\n",
       "      <td>3.1917</td>\n",
       "      <td>73400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-114.57</td>\n",
       "      <td>33.57</td>\n",
       "      <td>20</td>\n",
       "      <td>1454</td>\n",
       "      <td>326</td>\n",
       "      <td>624</td>\n",
       "      <td>262</td>\n",
       "      <td>1.9250</td>\n",
       "      <td>65500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  median age  T_room  T_bedroom  population  households  \\\n",
       "0    -114.31     34.19          15    5612       1283        1015         472   \n",
       "1    -114.47     34.40          19    7650       1901        1129         463   \n",
       "2    -114.56     33.69          17     720        174         333         117   \n",
       "3    -114.57     33.64          14    1501        337         515         226   \n",
       "4    -114.57     33.57          20    1454        326         624         262   \n",
       "\n",
       "   income  price  \n",
       "0  1.4936  66900  \n",
       "1  1.8200  80100  \n",
       "2  1.6509  85700  \n",
       "3  3.1917  73400  \n",
       "4  1.9250  65500  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kundan kumar\\Desktop\\housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1431e+02  3.4190e+01  1.5000e+01 ...  4.7200e+02  1.4936e+00\n",
      "   6.6900e+04]\n",
      " [-1.1447e+02  3.4400e+01  1.9000e+01 ...  4.6300e+02  1.8200e+00\n",
      "   8.0100e+04]\n",
      " [-1.1456e+02  3.3690e+01  1.7000e+01 ...  1.1700e+02  1.6509e+00\n",
      "   8.5700e+04]\n",
      " ...\n",
      " [-1.1694e+02  3.2830e+01  3.8000e+01 ...  3.0400e+02  3.7831e+00\n",
      "   1.4780e+05]\n",
      " [-1.1694e+02  3.2820e+01  3.5000e+01 ...  2.9400e+02  3.2411e+00\n",
      "   1.5920e+05]\n",
      " [-1.1694e+02  3.2800e+01  2.8000e+01 ...  7.0300e+02  2.4141e+00\n",
      "   1.3750e+05]]\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[:,0:10]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_scale = min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 9) (160, 9) (239,) (160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.4)\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1106 21:21:57.000486  9000 deprecation.py:323] From C:\\Users\\kundan kumar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(9,)), #input layer\n",
    "    Dense(32, activation='relu'), ## hidden layer \n",
    "    Dense(1, activation='sigmoid'), ##output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer=sgd(lr = 0.05),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1106 21:21:58.820618  9000 deprecation_wrapper.py:119] From C:\\Users\\kundan kumar\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 239 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "239/239 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "239/239 [==============================] - 0s 121us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "239/239 [==============================] - 0s 69us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "239/239 [==============================] - 0s 85us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "239/239 [==============================] - 0s 99us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "239/239 [==============================] - 0s 99us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "239/239 [==============================] - 0s 99us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "239/239 [==============================] - 0s 101us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "239/239 [==============================] - 0s 68us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "239/239 [==============================] - 0s 72us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "239/239 [==============================] - 0s 89us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "239/239 [==============================] - 0s 59us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "239/239 [==============================] - 0s 74us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "239/239 [==============================] - 0s 77us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "239/239 [==============================] - 0s 62us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "239/239 [==============================] - 0s 64us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "239/239 [==============================] - 0s 74us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "239/239 [==============================] - 0s 64us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "239/239 [==============================] - 0s 61us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "239/239 [==============================] - 0s 53us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "239/239 [==============================] - 0s 61us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "239/239 [==============================] - 0s 52us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "239/239 [==============================] - 0s 64us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "239/239 [==============================] - 0s 72us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "239/239 [==============================] - 0s 37us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "239/239 [==============================] - 0s 66us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "239/239 [==============================] - 0s 78us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "239/239 [==============================] - 0s 55us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "239/239 [==============================] - 0s 79us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "239/239 [==============================] - 0s 63us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "239/239 [==============================] - 0s 40us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "239/239 [==============================] - 0s 54us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "239/239 [==============================] - 0s 52us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "239/239 [==============================] - 0s 74us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "239/239 [==============================] - 0s 62us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "239/239 [==============================] - 0s 53us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "239/239 [==============================] - 0s 65us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "239/239 [==============================] - 0s 62us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "239/239 [==============================] - 0s 48us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "239/239 [==============================] - 0s 67us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "239/239 [==============================] - 0s 36us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "239/239 [==============================] - 0s 74us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "239/239 [==============================] - 0s 41us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "239/239 [==============================] - 0s 64us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "239/239 [==============================] - 0s 71us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "239/239 [==============================] - 0s 46us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "239/239 [==============================] - 0s 42us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "239/239 [==============================] - 0s 63us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "239/239 [==============================] - 0s 63us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "239/239 [==============================] - 0s 76us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "239/239 [==============================] - 0s 64us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "239/239 [==============================] - 0s 71us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "239/239 [==============================] - 0s 62us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "239/239 [==============================] - 0s 57us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "239/239 [==============================] - 0s 61us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "239/239 [==============================] - 0s 50us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "239/239 [==============================] - 0s 51us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "239/239 [==============================] - 0s 87us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "239/239 [==============================] - 0s 84us/step - loss: nan - accuracy: 0.0000e+00 - val_loss: nan - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,batch_size=32, epochs=100,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGIFJREFUeJzt3X+QXWWd5/H3xyQQFEJICD+bmCBsaQCNoUUZ3RLlhzA7/BDZgYysGcShHMd1R4oto84uis4OuOOIru66jIKoIxFxKRmdkUGUqXXHERKMq4BMYoSlIUJIEETlR/C7f9wTuDS36U76dN80eb+qbt1znvOcc75Puiqffs6593SqCkmSxut5/S5AkvTcYKBIklphoEiSWmGgSJJaYaBIklphoEiSWmGgSBMsyYIklWT6GPr+YZLvjvc4Uj8YKFKXJHckeSzJnsPaVzf/mS/oT2XS9s9AkZ7pZ8DSLStJDgN26V850tRgoEjP9AXgLV3ry4DPd3dIsnuSzyfZkOTOJH+W5HnNtmlJ/jLJ/UnWAf+mx76fTbI+yd1JPpxk2tYWmWS/JNck2ZRkbZI/6tp2RJKVSR5Kcm+Sv2raZyb5YpKNSX6R5KYke2/tuaVeDBTpmf4ZmJXkJc1/9KcDXxzW578BuwMHAq+lE0BnNdv+CPg94OXAIHDasH0vBzYDBzV9jgPetg11XgEMAfs15/gvSY5utn0c+HhVzQJeBFzZtC9r6j4AmAu8HfjNNpxbegYDReptyyzlWOAnwN1bNnSFzHur6pdVdQfwUeDfNV1+H7i4qu6qqk3AX3TtuzdwAvCnVfWrqroP+BhwxtYUl+QA4DXAe6rqkapaDXymq4bHgYOS7FlVD1fVP3e1zwUOqqonqmpVVT20NeeWRmKgSL19AfgD4A8ZdrkL2BPYCbizq+1OYP9meT/grmHbtnghMANY31xy+gXwP4G9trK+/YBNVfXLEWo4G/hXwE+ay1q/1zWua4EVSe5J8pEkM7by3FJPBorUQ1XdSefm/O8C/2vY5vvp/Kb/wq62+Tw1i1lP55JS97Yt7gIeBfasqtnNa1ZVHbKVJd4DzEmyW68aqmpNVS2lE1QXAVcleUFVPV5VH6yqRcDv0Lk09xakFhgo0sjOBl5fVb/qbqyqJ+jck/jzJLsleSFwLk/dZ7kSeFeSgSR7AMu79l0P/APw0SSzkjwvyYuSvHZrCququ4B/Av6iudH+0qbevwFIcmaSeVX1W+AXzW5PJHldksOay3YP0QnGJ7bm3NJIDBRpBFX106paOcLmfw/8ClgHfBf4EnBps+2v6VxW+iFwM8+c4byFziWzW4EHgKuAfbehxKXAAjqzlauB86vqumbb8cAtSR6mc4P+jKp6BNinOd9DwG3AP/LMDxxI2yT+gS1JUhucoUiSWmGgSJJaYaBIklphoEiSWrFDPQZ7zz33rAULFvS7DEmaUlatWnV/Vc0brd8OFSgLFixg5cqRPgUqSeolyZ2j9/KSlySpJQaKJKkVBookqRU71D0USRqrxx9/nKGhIR555JF+lzJpZs6cycDAADNmbNsDqA0USephaGiI3XbbjQULFpCk3+VMuKpi48aNDA0NsXDhwm06hpe8JKmHRx55hLlz5+4QYQKQhLlz545rRmagSNIIdpQw2WK84zVQJEmtMFAkaTu0ceNGFi9ezOLFi9lnn33Yf//9n1x/7LHHxnSMs846i9tvv32CK32KN+UlaTs0d+5cVq9eDcAHPvABdt11V84777yn9akqqornPa/33OCyyy6b8Dq7OUORpClk7dq1HHroobz97W9nyZIlrF+/nnPOOYfBwUEOOeQQLrjggif7vuY1r2H16tVs3ryZ2bNns3z5cl72spdx5JFHct9997VemzMUSRrFB//2Fm6956FWj7lov1mcf+Ih27TvrbfeymWXXcanP/1pAC688ELmzJnD5s2bed3rXsdpp53GokWLnrbPgw8+yGtf+1ouvPBCzj33XC699FKWL18+7nF0c4YiSVPMi170Il7xilc8uX7FFVewZMkSlixZwm233catt976jH122WUXTjjhBAAOP/xw7rjjjtbrcoYiSaPY1pnERHnBC17w5PKaNWv4+Mc/zo033sjs2bM588wze36XZKeddnpyedq0aWzevLn1upyhSNIU9tBDD7Hbbrsxa9Ys1q9fz7XXXtu3WpyhSNIUtmTJEhYtWsShhx7KgQceyKtf/eq+1ZKq6tvJJ9vg4GD5B7YkjcVtt93GS17ykn6XMel6jTvJqqoaHG1fL3lJklphoEiSWmGgSJJaYaBIklphoEiSWmGgSJJaYaBI0nboqKOOesaXFC+++GLe8Y53jLjPrrvuOtFlPSsDRZK2Q0uXLmXFihVPa1uxYgVLly7tU0Wj62ugJDk+ye1J1iZ5xmMvk+yc5MvN9u8nWTBs+/wkDyc5b/i+kjSVnXbaaXz961/n0UcfBeCOO+7gnnvuYfHixRx99NEsWbKEww47jK997Wt9rvQpfXv0SpJpwKeAY4Eh4KYk11RV92MyzwYeqKqDkpwBXASc3rX9Y8DfT1bNknZQf78cfv6jdo+5z2FwwoUjbp47dy5HHHEE3/zmNzn55JNZsWIFp59+OrvssgtXX301s2bN4v777+dVr3oVJ5100rj/Hnwb+jlDOQJYW1XrquoxYAVw8rA+JwOXN8tXAUen+VdLcgqwDrhlkuqVpEnVfdlry+WuquJ973sfL33pSznmmGO4++67uffee/tcaUc/Hw65P3BX1/oQ8MqR+lTV5iQPAnOT/AZ4D53ZzbNe7kpyDnAOwPz589upXNKO5VlmEhPplFNO4dxzz+Xmm2/mN7/5DUuWLOFzn/scGzZsYNWqVcyYMYMFCxb0fFx9P/RzhtJrfjb8SZUj9fkg8LGqeni0k1TVJVU1WFWD8+bN24YyJak/dt11V4466ije+ta3Pnkz/sEHH2SvvfZixowZfOc73+HOO+/sc5VP6ecMZQg4oGt9ALhnhD5DSaYDuwOb6MxkTkvyEWA28Nskj1TVJye+bEmaPEuXLuXUU0998tLXm9/8Zk488UQGBwdZvHgxL37xi/tc4VP6GSg3AQcnWQjcDZwB/MGwPtcAy4DvAacB367O8/b/9ZYOST4APGyYSHoueuMb30j3nxnZc889+d73vtez78MPj3rRZkL1LVCaeyLvBK4FpgGXVtUtSS4AVlbVNcBngS8kWUtnZnJGv+qVJD27vv7Fxqr6O+DvhrX9567lR4B/O8oxPjAhxUmStorflJekEexIf9EWxj9eA0WSepg5cyYbN27cYUKlqti4cSMzZ87c5mP09ZKXJG2vBgYGGBoaYsOGDf0uZdLMnDmTgYGBbd7fQJGkHmbMmMHChQv7XcaU4iUvSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUisMFElSKwwUSVIrDBRJUiv6GihJjk9ye5K1SZb32L5zki8327+fZEHTfmySVUl+1Ly/frJrlyQ9Xd8CJck04FPACcAiYGmSRcO6nQ08UFUHAR8DLmra7wdOrKrDgGXAFyanaknSSPo5QzkCWFtV66rqMWAFcPKwPicDlzfLVwFHJ0lV/aCq7mnabwFmJtl5UqqWJPXUz0DZH7ira32oaevZp6o2Aw8Cc4f1eRPwg6p6dILqlCSNwfQ+njs92mpr+iQ5hM5lsONGPElyDnAOwPz587e+SknSmPRzhjIEHNC1PgDcM1KfJNOB3YFNzfoAcDXwlqr66UgnqapLqmqwqgbnzZvXYvmSpG79DJSbgIOTLEyyE3AGcM2wPtfQuekOcBrw7aqqJLOBbwDvrar/M2kVS5JG1LdAae6JvBO4FrgNuLKqbklyQZKTmm6fBeYmWQucC2z5aPE7gYOA/5RkdfPaa5KHIEnqkqrhty2euwYHB2vlypX9LkOSppQkq6pqcLR+flNektQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1AoDRZLUCgNFktQKA0WS1IoxBUqSFyXZuVk+Ksm7ksye2NIkSVPJWGcoXwWeSHIQ8FlgIfClCatKkjTljDVQfltVm4E3AhdX1buBfSeuLEnSVDPWQHk8yVJgGfD1pm3GxJQkSZqKxhooZwFHAn9eVT9LshD44sSVJUmaasYUKFV1a1W9q6quSLIHsFtVXTjekyc5PsntSdYmWd5j+85Jvtxs/36SBV3b3tu0357kDeOtRZI0PmP9lNcNSWYlmQP8ELgsyV+N58RJpgGfAk4AFgFLkywa1u1s4IGqOgj4GHBRs+8i4AzgEOB44L83x5Mk9clYL3ntXlUPAacCl1XV4cAx4zz3EcDaqlpXVY8BK4CTh/U5Gbi8Wb4KODpJmvYVVfVoVf0MWNscT5LUJ2MNlOlJ9gV+n6duyo/X/sBdXetDTVvPPs2nzB4E5o5xXwCSnJNkZZKVGzZsaKl0SdJwYw2UC4BrgZ9W1U1JDgTWjPPc6dFWY+wzln07jVWXVNVgVQ3OmzdvK0uUJI3V9LF0qqqvAF/pWl8HvGmc5x4CDuhaHwDuGaHPUJLpwO7ApjHuK0maRGO9KT+Q5Ook9yW5N8lXkwyM89w3AQcnWZhkJzo32a8Z1ucaOt99ATgN+HZVVdN+RvMpsIXAwcCN46xHkjQOY73kdRmd/8T3o3Ov4m+btm3W3BN5J51LabcBV1bVLUkuSHJS0+2zwNwka4FzgeXNvrcAVwK3At8E/qSqnhhPPZKk8UnnF/5ROiWrq2rxaG3bu8HBwVq5cmW/y5CkKSXJqqoaHK3fWGco9yc5M8m05nUmsHF8JUqSnkvGGihvpfOR4Z8D6+nczzhrooqSJE09Y330yv+rqpOqal5V7VVVp9D5kqMkScD4/mLjua1VIUma8sYTKL2+XChJ2kGNJ1BG/3iYJGmH8azflE/yS3oHR4BdJqQiSdKU9KyBUlW7TVYhkqSpbTyXvCRJepKBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJakVfAiXJnCTXJVnTvO8xQr9lTZ81SZY1bc9P8o0kP0lyS5ILJ7d6SVIv/ZqhLAeur6qDgeub9adJMgc4H3glcARwflfw/GVVvRh4OfDqJCdMTtmSpJH0K1BOBi5vli8HTunR5w3AdVW1qaoeAK4Djq+qX1fVdwCq6jHgZmBgEmqWJD2LfgXK3lW1HqB536tHn/2Bu7rWh5q2JyWZDZxIZ5YjSeqj6RN14CTfAvbpsen9Yz1Ej7bqOv504ArgE1W17lnqOAc4B2D+/PljPLUkaWtNWKBU1TEjbUtyb5J9q2p9kn2B+3p0GwKO6lofAG7oWr8EWFNVF49SxyVNXwYHB+vZ+kqStl2/LnldAyxrlpcBX+vR51rguCR7NDfjj2vaSPJhYHfgTyehVknSGPQrUC4Ejk2yBji2WSfJYJLPAFTVJuBDwE3N64Kq2pRkgM5ls0XAzUlWJ3lbPwYhSXpKqnacq0CDg4O1cuXKfpchSVNKklVVNThaP78pL0lqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqhYEiSWqFgSJJaoWBIklqRV8CJcmcJNclWdO87zFCv2VNnzVJlvXYfk2SH098xZKk0fRrhrIcuL6qDgaub9afJskc4HzglcARwPndwZPkVODhySlXkjSafgXKycDlzfLlwCk9+rwBuK6qNlXVA8B1wPEASXYFzgU+PAm1SpLGoF+BsndVrQdo3vfq0Wd/4K6u9aGmDeBDwEeBX492oiTnJFmZZOWGDRvGV7UkaUTTJ+rASb4F7NNj0/vHeogebZVkMXBQVb07yYLRDlJVlwCXAAwODtYYzy1J2koTFihVdcxI25Lcm2TfqlqfZF/gvh7dhoCjutYHgBuAI4HDk9xBp/69ktxQVUchSeqbfl3yugbY8qmtZcDXevS5FjguyR7NzfjjgGur6n9U1X5VtQB4DfAvhokk9V+/AuVC4Ngka4Bjm3WSDCb5DEBVbaJzr+Sm5nVB0yZJ2g6lase5rTA4OFgrV67sdxmSNKUkWVVVg6P185vykqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVhgokqRWGCiSpFYYKJKkVqSq+l3DpEmyAbiz33VspT2B+/tdxCRzzDsGxzx1vLCq5o3WaYcKlKkoycqqGux3HZPJMe8YHPNzj5e8JEmtMFAkSa0wULZ/l/S7gD5wzDsGx/wc4z0USVIrnKFIklphoEiSWmGgbAeSzElyXZI1zfseI/Rb1vRZk2RZj+3XJPnxxFc8fuMZc5LnJ/lGkp8kuSXJhZNb/dZJcnyS25OsTbK8x/adk3y52f79JAu6tr23ab89yRsms+7x2NYxJzk2yaokP2reXz/ZtW+L8fyMm+3zkzyc5LzJqnlCVJWvPr+AjwDLm+XlwEU9+swB1jXvezTLe3RtPxX4EvDjfo9noscMPB94XdNnJ+B/Ayf0e0wjjHMa8FPgwKbWHwKLhvV5B/DpZvkM4MvN8qKm/87AwuY40/o9pgke88uB/ZrlQ4G7+z2eiRxv1/avAl8Bzuv3eMbzcoayfTgZuLxZvhw4pUefNwDXVdWmqnoAuA44HiDJrsC5wIcnoda2bPOYq+rXVfUdgKp6DLgZGJiEmrfFEcDaqlrX1LqCzti7df9bXAUcnSRN+4qqerSqfgasbY63vdvmMVfVD6rqnqb9FmBmkp0npeptN56fMUlOofPL0i2TVO+EMVC2D3tX1XqA5n2vHn32B+7qWh9q2gA+BHwU+PVEFtmy8Y4ZgCSzgROB6yeozvEadQzdfapqM/AgMHeM+26PxjPmbm8CflBVj05QnW3Z5vEmeQHwHuCDk1DnhJve7wJ2FEm+BezTY9P7x3qIHm2VZDFwUFW9e/h12X6bqDF3HX86cAXwiapat/UVTopnHcMofcay7/ZoPGPubEwOAS4CjmuxrokynvF+EPhYVT3cTFimNANlklTVMSNtS3Jvkn2ran2SfYH7enQbAo7qWh8AbgCOBA5Pcgedn+deSW6oqqPoswkc8xaXAGuq6uIWyp0oQ8ABXesDwD0j9BlqQnJ3YNMY990ejWfMJBkArgbeUlU/nfhyx208430lcFqSjwCzgd8meaSqPjnxZU+Aft/E8VUA/5Wn36D+SI8+c4Cf0bkpvUezPGdYnwVMnZvy4xoznftFXwWe1++xjDLO6XSujy/kqRu2hwzr8yc8/Ybtlc3yITz9pvw6psZN+fGMeXbT/039HsdkjHdYnw8wxW/K970AXwWda8fXA2ua9y3/aQ4Cn+nq91Y6N2bXAmf1OM5UCpRtHjOd3wALuA1Y3bze1u8xPctYfxf4FzqfBHp/03YBcFKzPJPOJ3zWAjcCB3bt+/5mv9vZTj/J1uaYgT8DftX1c10N7NXv8Uzkz7jrGFM+UHz0iiSpFX7KS5LUCgNFktQKA0WS1AoDRZLUCgNFktQKA0VqUZInkqzuej3jybPjOPaCqfI0ae2Y/Ka81K7fVNXifhch9YMzFGkSJLkjyUVJbmxeBzXtL0xyfZL/27zPb9r3TnJ1kh82r99pDjUtyV83fwfmH5Ls0rdBScMYKFK7dhl2yev0rm0PVdURwCeBLc8f+yTw+ap6KfA3wCea9k8A/1hVLwOW8NSjzQ8GPlVVhwC/oPNEXmm74DflpRYlebiqdu3Rfgfw+qpal2QG8POqmpvkfmDfqnq8aV9fVXsm2QAMVNej25unSV9XVQc36+8BZlTVVPo7OHoOc4YiTZ4aYXmkPr10/22QJ/A+qLYjBoo0eU7vev9es/xPdJ4+C/Bm4LvN8vXAHwMkmZZk1mQVKW0rf7uR2rVLktVd69+sqi0fHd45yffp/CK3tGl7F3Bpkv8IbADOatr/A3BJkrPpzET+GFg/4dVL4+A9FGkSNPdQBqvq/n7XIk0UL3lJklrhDEWS1ApnKJKkVhgokqRWGCiSpFYYKJKkVhgokqRW/H9xX6/lmKITiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kundan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\kundan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\kundan kumar\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([110900.,  67500.,  67500., 167800., 174400., 318100.,  67500.,\n",
       "       137500., 158300., 300300., 274600., 116300.,  87500.,  94400.,\n",
       "        97200.,  67500.,  45000., 140600., 258100., 134600.,  30000.,\n",
       "        67500., 187200., 158300.,  67500., 167800., 139500., 100000.,\n",
       "       143400.,  90900., 134600.,  69400.,  65600., 143800.,  70100.,\n",
       "       140600., 166300.,  59200.,  94500.,  62000., 139500., 147800.,\n",
       "        65800.,  57400., 199200.,  57400., 165300.,  46700.,  55000.,\n",
       "        88400.,  68900., 104100.,  57400., 143800., 137500.,  67500.,\n",
       "        97200.,  84700.,  58800., 194500.,  67500., 197600.,  68600.,\n",
       "        67500., 143400.,  94400., 142500.,  95800.,  67500., 147800.,\n",
       "       159000., 177800.,  69400.,  81000., 142500.,  57400.,  87500.,\n",
       "        73600.,  57400.,  58800., 100000.,  66400.,  65600.,  57400.,\n",
       "        87500.,  67500., 258100.,  87500.,  57400.,  67500.,  99100.,\n",
       "       167400., 187200., 143800.,  94400., 166300.,  55000.,  87500.,\n",
       "       104200.,  42500.,  87500.,  65600.,  87500., 234500., 167800.,\n",
       "        54400., 318100., 187200.,  67500., 189700., 140000., 100000.,\n",
       "        67500., 300300., 258100.,  67500., 258100., 177800., 104200.,\n",
       "       143800.,  69400., 189700., 100000., 123400., 187200.,  87500.,\n",
       "        68900.,  61400.,  65900., 143800.,  87500., 137500.,  73600.,\n",
       "        43300.,  65600.,  60600., 142300.,  98700.,  67500., 189700.,\n",
       "        69400.,  68900., 171500., 187200., 189700., 234500.,  87500.,\n",
       "       159100.,  65600., 143800.,  87500., 139500., 143800., 187200.,\n",
       "       113600., 187200., 187200.,  68900.,  67500.,  46700.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([134500.,  64000.,  68200., 110100., 159500., 148900.,  70800.,\n",
       "       110700., 170700., 316400., 239900., 146300., 102800., 100000.,\n",
       "        27500.,  60800.,  32900., 166700., 248100.,  97500.,  41000.,\n",
       "        62300., 211900., 127900.,  79200.,  83200.,  84300., 214300.,\n",
       "       163100.,  66600., 138300.,  67500.,  78500., 112500.,  72600.,\n",
       "        94800., 160400.,  64400.,  47500.,  54200., 150000., 226500.,\n",
       "        48100.,  66000., 221000.,  69100., 143000.,  67700.,  44000.,\n",
       "        86500.,  77700.,  89600.,  68200., 170200., 113500.,  67500.,\n",
       "        32500.,  80100.,  53600., 158500., 100900., 214500.,  50000.,\n",
       "        94900.,  90800.,  93800.,  91800.,  61000.,  80800., 161100.,\n",
       "       500001., 230200.,  59400., 124700., 159900.,  64700.,  81300.,\n",
       "        72100.,  40000.,  58300.,  83000.,  84700., 112500.,  43900.,\n",
       "       146300.,  59600., 145200.,  51300.,  62800.,  88500.,  92900.,\n",
       "       146400., 155700., 193800., 100000., 159200.,  50000., 172900.,\n",
       "        72700.,  47800.,  98100.,  81700.,  73400., 231800., 181300.,\n",
       "        42500., 153500., 202100.,  80900., 137600.,  81700., 127100.,\n",
       "        76200., 294700., 183900.,  71700., 235600., 199400., 121500.,\n",
       "       155000.,  82200., 112800.,  96300.,  74400., 206100.,  85200.,\n",
       "        54600.,  61200.,  66700., 103100., 145000., 115300.,  86200.,\n",
       "        40000.,  66900.,  61100., 137500.,  88400.,  58600., 238800.,\n",
       "        82400.,  71800., 185300., 184600., 168800., 167200.,  91100.,\n",
       "        93400.,  69600., 193800.,  61000.,  81000., 345500., 170100.,\n",
       "        93800., 146900., 189200.,  60600.,  90800.,  63700.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7280334728033473"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
